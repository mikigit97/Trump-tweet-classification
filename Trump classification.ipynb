{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "04bca87d",
      "metadata": {
        "id": "04bca87d"
      },
      "outputs": [],
      "source": [
        "# trump_author_attribution.py â€“ *Extended* solution for AssignmentÂ 3\n",
        "# --------------------------------------------------------------\n",
        "# Supports **four** algorithms selectable via --algo <name>\n",
        "#   1. baseline   â€“ TFâ€‘IDF  + LogisticÂ Regression (as before)\n",
        "#   2. svm        â€“ TFâ€‘IDF  + LinearÂ SVM\n",
        "#   3. mlp        â€“ TFâ€‘IDF  + 2â€‘layer feedâ€‘forward neural net\n",
        "#   4. transformer â€“ DistilBERT fineâ€‘tuning (requires GPU & ğŸ¤—)\n",
        "# Produces <algo>_preds.txt in the required singleâ€‘line format.\n",
        "# --------------------------------------------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from __future__ import annotations\n",
        "import os, re, string, pickle, argparse, sys\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ scikitâ€‘learn components â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "# Add these imports at the top\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch.nn.functional as F\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "# Add these imports at the top\n",
        "from transformers import (\n",
        "    DistilBertTokenizer,\n",
        "    DistilBertForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "D-ugg_1nBy04",
      "metadata": {
        "id": "D-ugg_1nBy04"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"]=\"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e469d60",
      "metadata": {
        "id": "0e469d60"
      },
      "source": [
        "## Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "97028d9c",
      "metadata": {
        "id": "97028d9c"
      },
      "outputs": [],
      "source": [
        "class TweetDataset(Dataset):\n",
        "    \"\"\"Custom Dataset for tweet classification with DistilBERT\"\"\"\n",
        "\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Tokenize the text\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bb6c8a8",
      "metadata": {
        "id": "3bb6c8a8"
      },
      "source": [
        "## Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "65a82db4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65a82db4",
        "outputId": "cd11bf37-04b1-465d-b942-7d15c5cab316"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "import string\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Initialize preprocessing tools\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Enhanced preprocessing for tweet text with common tweet-specific issues\n",
        "    \"\"\"\n",
        "    if pd.isna(text) or text == '':\n",
        "        return ''\n",
        "\n",
        "    # Convert to string and lowercase\n",
        "    text = str(text).lower()\n",
        "\n",
        "    # Handle HTML entities and special characters\n",
        "    text = re.sub(r'&amp;', 'and', text)\n",
        "    text = re.sub(r'&lt;', '<', text)\n",
        "    text = re.sub(r'&gt;', '>', text)\n",
        "    text = re.sub(r'&quot;', '\"', text)\n",
        "    text = re.sub(r'&apos;', \"'\", text)\n",
        "\n",
        "    # Remove URLs (more comprehensive)\n",
        "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
        "    text = re.sub(r'www\\.(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
        "    text = re.sub(r't\\.co/\\w+', '', text)  # Twitter's URL shortener\n",
        "\n",
        "    # Remove user mentions (@username) but keep the context\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "\n",
        "    # Handle hashtags - remove # but keep the word\n",
        "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
        "\n",
        "    # Handle retweets\n",
        "    text = re.sub(r'^rt\\s+', '', text)  # Remove RT at beginning\n",
        "    text = re.sub(r'\\brt\\b', '', text)  # Remove standalone RT\n",
        "\n",
        "    # Handle contractions and common abbreviations\n",
        "    contractions = {\n",
        "        \"won't\": \"will not\", \"can't\": \"cannot\", \"n't\": \" not\",\n",
        "        \"'re\": \" are\", \"'ve\": \" have\", \"'ll\": \" will\", \"'d\": \" would\",\n",
        "        \"'m\": \" am\", \"thx\": \"thanks\", \"u\": \"you\", \"ur\": \"your\",\n",
        "        \"ppl\": \"people\", \"govt\": \"government\", \"b4\": \"before\"\n",
        "    }\n",
        "    for contraction, expansion in contractions.items():\n",
        "        text = re.sub(contraction, expansion, text)\n",
        "\n",
        "    # Handle repeated characters (e.g., \"sooooo\" -> \"so\")\n",
        "    text = re.sub(r'(.)\\1{2,}', r'\\1', text)\n",
        "\n",
        "    # Remove excessive whitespace and newlines\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'\\n+', ' ', text)\n",
        "\n",
        "    # Remove punctuation but preserve emoticons/emoji patterns first\n",
        "    # Simple emoticon preservation\n",
        "    emoticon_pattern = r'[;:=8][\\-o\\*\\']?[\\)\\]\\(\\[dDpP/\\\\OpP]'\n",
        "    emoticons = re.findall(emoticon_pattern, text)\n",
        "\n",
        "    # Remove punctuation and numbers\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Tokenize\n",
        "    try:\n",
        "        tokens = word_tokenize(text)\n",
        "    except:\n",
        "        tokens = text.split()\n",
        "\n",
        "    # Remove stopwords, short words, and lemmatize\n",
        "    tokens = [\n",
        "        lemmatizer.lemmatize(token)\n",
        "        for token in tokens\n",
        "        if token not in stop_words\n",
        "        and len(token) > 2\n",
        "        and token.isalpha()  # Only keep alphabetic tokens\n",
        "    ]\n",
        "\n",
        "    # Add back emoticons as tokens\n",
        "    tokens.extend(emoticons)\n",
        "\n",
        "    # Remove empty tokens and duplicates while preserving order\n",
        "    seen = set()\n",
        "    clean_tokens = []\n",
        "    for token in tokens:\n",
        "        if token and token not in seen:\n",
        "            clean_tokens.append(token)\n",
        "            seen.add(token)\n",
        "\n",
        "    result = ' '.join(clean_tokens)\n",
        "    return result if result.strip() else 'empty_tweet'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "17adce48",
      "metadata": {
        "id": "17adce48"
      },
      "outputs": [],
      "source": [
        "def preprocess_train_data(train_fn: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Load and preprocess data\n",
        "    cols = ['tweet_id','user_handle','tweet','timestamp','device']\n",
        "    train_df = pd.read_csv(train_fn, sep=\"\\t\", header=None, names=cols, quoting=3, index_col=False)\n",
        "    # print(f\"First value in the 'user_handle' column: {train_df['user_handle'].iloc[0]}\")\n",
        "    # print(train_df.head())\n",
        "\n",
        "    train_df = train_df[train_df['user_handle'] == 'realDonaldTrump']\n",
        "\n",
        "    print(f\"Shape of the original dataset: {train_df.shape}\")\n",
        "\n",
        "\n",
        "\n",
        "    # Filter for Android and iPhone only\n",
        "    # device_mapping = {'android': 'android', 'iphone': 'iphone'}\n",
        "    # train_clean = train_df[train_df['device'].isin(device_mapping.keys())].copy()\n",
        "    train_df['device'] = train_df['device'].apply(lambda x: 'iphone' if x != 'android' else x)\n",
        "\n",
        "    train_df['processed_tweet'] = train_df['tweet'].apply(preprocess_text)\n",
        "\n",
        "    return train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3798cb1f",
      "metadata": {
        "id": "3798cb1f"
      },
      "source": [
        "## Feature extraction\n",
        "### We've extracted time features from the timestamp column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "33f23d52",
      "metadata": {
        "id": "33f23d52"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def extract_timestamp_features(df):\n",
        "    \"\"\"\n",
        "    Extract temporal features from timestamp column\n",
        "    \"\"\"\n",
        "    # Convert timestamp to datetime\n",
        "    df['datetime'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
        "    # print(f\"first 5 rows of the 'datetime' column:\\n{df['datetime'].head()}\")\n",
        "    # # Drop rows with invalid datetime\n",
        "    # df = df.dropna(subset=['datetime'])\n",
        "\n",
        "    # Extract temporal features\n",
        "    df['hour_of_day'] = df['datetime'].dt.hour\n",
        "    df['day_of_week'] = df['datetime'].dt.dayofweek  # Monday=0, Sunday=6\n",
        "    df['day_of_month'] = df['datetime'].dt.day\n",
        "    df['month'] = df['datetime'].dt.month\n",
        "    df['year'] = df['datetime'].dt.year\n",
        "\n",
        "    # Weekend indicator (Saturday=5, Sunday=6)\n",
        "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
        "\n",
        "    # Season (Northern Hemisphere)\n",
        "    def get_season(month):\n",
        "        if month in [12, 1, 2]:\n",
        "            return 0  # Winter\n",
        "        elif month in [3, 4, 5]:\n",
        "            return 1  # Spring\n",
        "        elif month in [6, 7, 8]:\n",
        "            return 2  # Summer\n",
        "        else:\n",
        "            return 3  # Fall\n",
        "\n",
        "    df['season'] = df['month'].apply(get_season)\n",
        "\n",
        "    # Time of day categories\n",
        "    def get_time_period(hour):\n",
        "        if 6 <= hour < 12:\n",
        "            return 0  # Morning\n",
        "        elif 12 <= hour < 18:\n",
        "            return 1  # Afternoon\n",
        "        elif 18 <= hour < 22:\n",
        "            return 2  # Evening\n",
        "        else:\n",
        "            return 3  # Night\n",
        "\n",
        "    df['time_period'] = df['hour_of_day'].apply(get_time_period)\n",
        "\n",
        "    # Business hours indicator (9 AM to 5 PM, weekdays)\n",
        "    df['is_business_hours'] = ((df['hour_of_day'] >= 9) &\n",
        "                               (df['hour_of_day'] < 17) &\n",
        "                               (df['day_of_week'] < 5)).astype(int)\n",
        "\n",
        "    # Late night indicator (11 PM to 6 AM)\n",
        "    df['is_late_night'] = ((df['hour_of_day'] >= 23) |\n",
        "                           (df['hour_of_day'] < 6)).astype(int)\n",
        "\n",
        "    # for any null values in one of the column created, fill with mod value\n",
        "    for col in ['hour_of_day', 'day_of_week', 'day_of_month', 'month', 'year',\n",
        "                'is_weekend', 'season', 'time_period', 'is_business_hours',\n",
        "                'is_late_night']:\n",
        "        if df[col].isnull().any():\n",
        "            try:\n",
        "                mod_value = df[col].mode()[0]  # Get the most common value\n",
        "            except:\n",
        "                print(df[col])\n",
        "            # mod_value = df[col].mode()[0]\n",
        "            df[col].fillna(mod_value, inplace=True)\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c12b3e44",
      "metadata": {
        "id": "c12b3e44"
      },
      "source": [
        "## Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ndPzgpHkaRgv",
      "metadata": {
        "id": "ndPzgpHkaRgv"
      },
      "outputs": [],
      "source": [
        "# Define the neural network architecture\n",
        "class FFNNClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_sizes=[512, 256, 128], dropout_rate=0.3):\n",
        "        super(FFNNClassifier, self).__init__()\n",
        "\n",
        "        # Create layers dynamically\n",
        "        layers = []\n",
        "        prev_size = input_size\n",
        "\n",
        "        for hidden_size in hidden_sizes:\n",
        "            layers.extend([\n",
        "                nn.Linear(prev_size, hidden_size),\n",
        "                nn.ReLU(),\n",
        "                nn.BatchNorm1d(hidden_size),\n",
        "                nn.Dropout(dropout_rate)\n",
        "            ])\n",
        "            prev_size = hidden_size\n",
        "\n",
        "        # Output layer\n",
        "        layers.append(nn.Linear(prev_size, 2))  # 2 classes: android/iphone\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "D7M1FqnscgEs",
      "metadata": {
        "id": "D7M1FqnscgEs"
      },
      "outputs": [],
      "source": [
        "def extract_rich_features(df):\n",
        "    \"\"\"\n",
        "    Extract comprehensive stylometric and linguistic features\n",
        "    \"\"\"\n",
        "    features = pd.DataFrame()\n",
        "\n",
        "    # Basic text statistics\n",
        "    features['text_length'] = df['tweet'].str.len()\n",
        "    features['word_count'] = df['tweet'].str.split().str.len()\n",
        "    features['avg_word_length'] = df['tweet'].apply(lambda x: np.mean([len(word) for word in str(x).split()]) if str(x).split() else 0)\n",
        "    features['sentence_count'] = df['tweet'].str.count(r'[.!?]+') + 1\n",
        "\n",
        "    # Character-level features\n",
        "    features['uppercase_ratio'] = df['tweet'].apply(lambda x: sum(1 for c in str(x) if c.isupper()) / max(len(str(x)), 1))\n",
        "    features['digit_ratio'] = df['tweet'].apply(lambda x: sum(1 for c in str(x) if c.isdigit()) / max(len(str(x)), 1))\n",
        "    features['space_ratio'] = df['tweet'].apply(lambda x: sum(1 for c in str(x) if c.isspace()) / max(len(str(x)), 1))\n",
        "    features['punctuation_ratio'] = df['tweet'].apply(lambda x: sum(1 for c in str(x) if c in string.punctuation) / max(len(str(x)), 1))\n",
        "\n",
        "    # Specific punctuation counts\n",
        "    features['exclamation_count'] = df['tweet'].str.count('!')\n",
        "    features['question_count'] = df['tweet'].str.count(r'\\?')\n",
        "    features['comma_count'] = df['tweet'].str.count(',')\n",
        "    features['period_count'] = df['tweet'].str.count(r'\\.')\n",
        "    features['ellipsis_count'] = df['tweet'].str.count(r'\\.{2,}')\n",
        "    features['dash_count'] = df['tweet'].str.count('-')\n",
        "    features['quote_count'] = df['tweet'].str.count('\"') + df['tweet'].str.count(\"'\")\n",
        "\n",
        "    # Twitter-specific features\n",
        "    features['mention_count'] = df['tweet'].str.count('@')\n",
        "    features['hashtag_count'] = df['tweet'].str.count('#')\n",
        "    features['url_count'] = df['tweet'].str.count('http') + df['tweet'].str.count('www')\n",
        "    features['retweet_indicator'] = df['tweet'].str.lower().str.startswith('rt').astype(int)\n",
        "\n",
        "    # Capitalization patterns\n",
        "    features['all_caps_words'] = df['tweet'].apply(lambda x: sum(1 for word in str(x).split() if word.isupper() and len(word) > 1))\n",
        "    features['title_case_words'] = df['tweet'].apply(lambda x: sum(1 for word in str(x).split() if word.istitle()))\n",
        "    features['starts_with_capital'] = df['tweet'].apply(lambda x: 1 if str(x) and str(x)[0].isupper() else 0)\n",
        "\n",
        "    # Repetition patterns\n",
        "    features['repeated_chars'] = df['tweet'].apply(lambda x: len(re.findall(r'(.)\\1{2,}', str(x))))\n",
        "    features['repeated_words'] = df['tweet'].apply(lambda x: len(str(x).split()) - len(set(str(x).lower().split())))\n",
        "\n",
        "    # Vocabulary richness\n",
        "    features['unique_word_ratio'] = df['tweet'].apply(lambda x: len(set(str(x).lower().split())) / max(len(str(x).split()), 1))\n",
        "\n",
        "    # Emotional indicators\n",
        "    features['positive_emoji'] = df['tweet'].str.count(r'[ğŸ˜€ğŸ˜ƒğŸ˜„ğŸ˜ğŸ˜†ğŸ˜…ğŸ˜‚ğŸ¤£ğŸ˜ŠğŸ˜‡ğŸ™‚ğŸ˜‰ğŸ˜ŒğŸ˜ğŸ¥°ğŸ˜˜ğŸ˜—ğŸ˜™ğŸ˜šğŸ˜‹ğŸ˜›ğŸ˜ğŸ˜œğŸ¤ªğŸ¤¨ğŸ§ğŸ¤“ğŸ˜ğŸ¤©ğŸ¥³ğŸ˜ğŸ˜’ğŸ˜ğŸ˜”ğŸ˜ŸğŸ˜•ğŸ™â˜¹ï¸ğŸ˜£ğŸ˜–ğŸ˜«ğŸ˜©ğŸ¥ºğŸ˜¢ğŸ˜­ğŸ˜¤ğŸ˜ ğŸ˜¡ğŸ¤¬ğŸ¤¯ğŸ˜³ğŸ¥µğŸ¥¶ğŸ˜±ğŸ˜¨ğŸ˜°ğŸ˜¥ğŸ˜“ğŸ¤—ğŸ¤”ğŸ¤­ğŸ¤«ğŸ¤¥ğŸ˜¶ğŸ˜ğŸ˜‘ğŸ˜¬ğŸ™„ğŸ˜¯ğŸ˜¦ğŸ˜§ğŸ˜®ğŸ˜²ğŸ¥±ğŸ˜´ğŸ¤¤ğŸ˜ªğŸ˜µğŸ¤ğŸ¥´ğŸ¤¢ğŸ¤®ğŸ¤§ğŸ˜·ğŸ¤’ğŸ¤•ğŸ¤‘ğŸ¤ ğŸ˜ˆğŸ‘¿ğŸ‘¹ğŸ‘ºğŸ¤¡ğŸ’©ğŸ‘»ğŸ’€â˜ ï¸ğŸ‘½ğŸ‘¾ğŸ¤–ğŸƒğŸ˜ºğŸ˜¸ğŸ˜¹ğŸ˜»ğŸ˜¼ğŸ˜½ğŸ™€ğŸ˜¿ğŸ˜¾]')\n",
        "    features['negative_emoji'] = df['tweet'].str.count(r'[ğŸ˜ğŸ˜”ğŸ˜ŸğŸ˜•ğŸ™â˜¹ï¸ğŸ˜£ğŸ˜–ğŸ˜«ğŸ˜©ğŸ¥ºğŸ˜¢ğŸ˜­ğŸ˜¤ğŸ˜ ğŸ˜¡ğŸ¤¬]')\n",
        "\n",
        "    # Linguistic style\n",
        "    features['first_person_pronouns'] = df['tweet'].str.lower().str.count(r'\\b(i|me|my|mine|myself)\\b')\n",
        "    features['second_person_pronouns'] = df['tweet'].str.lower().str.count(r'\\b(you|your|yours|yourself)\\b')\n",
        "    features['third_person_pronouns'] = df['tweet'].str.lower().str.count(r'\\b(he|she|it|they|him|her|them|his|hers|its|their|theirs)\\b')\n",
        "\n",
        "    # Common Trump-specific patterns\n",
        "    features['trump_phrases'] = df['tweet'].str.lower().str.count(r'\\b(great|tremendous|amazing|fantastic|incredible|believe me|folks|sad|fake|winner|loser)\\b')\n",
        "    features['superlatives'] = df['tweet'].str.lower().str.count(r'\\b(best|worst|greatest|biggest|smallest|most|least)\\b')\n",
        "    features['absolutist_words'] = df['tweet'].str.lower().str.count(r'\\b(always|never|all|none|every|nothing|everything|everyone|nobody)\\b')\n",
        "\n",
        "    # Fill NaN values\n",
        "    features = features.fillna(0)\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "_RNTL7g8gy8K",
      "metadata": {
        "id": "_RNTL7g8gy8K"
      },
      "outputs": [],
      "source": [
        "#### Functions for Bert\n",
        "\n",
        "# Use ORIGINAL tweet text for transformer (not heavily preprocessed)\n",
        "# Light preprocessing for transformers\n",
        "def light_preprocess_for_transformer(text):\n",
        "    \"\"\"Light preprocessing that preserves important stylistic features\"\"\"\n",
        "    if pd.isna(text) or text == '':\n",
        "        return ''\n",
        "\n",
        "    text = str(text)\n",
        "\n",
        "    # Only remove excessive whitespace and newlines\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'\\n+', ' ', text)\n",
        "\n",
        "    # Handle some HTML entities\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "    text = re.sub(r'&lt;', '<', text)\n",
        "    text = re.sub(r'&gt;', '>', text)\n",
        "    text = re.sub(r'&quot;', '\"', text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "# Define compute metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "410ebee3",
      "metadata": {
        "id": "410ebee3"
      },
      "source": [
        "## FFNN helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "efc60aa3",
      "metadata": {
        "id": "efc60aa3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def create_ffnn_param_grid():\n",
        "    \"\"\"Create parameter grid for FFNN\"\"\"\n",
        "    return {\n",
        "        'hidden_sizes': [[128], [256, 128], [256, 128]],\n",
        "        'dropout_rate': [0.2, 0.5],\n",
        "        'learning_rate': [0.001, 0.01],\n",
        "        'batch_size': [32],\n",
        "        'weight_decay': [1e-4]\n",
        "    }\n",
        "\n",
        "def train_ffnn_model(X_tensor, y_tensor, params, input_size):\n",
        "    \"\"\"Train a single FFNN model with given parameters\"\"\"\n",
        "    # Create data loaders\n",
        "    dataset = TensorDataset(X_tensor, y_tensor)\n",
        "    dataloader = DataLoader(dataset, batch_size=params['batch_size'], shuffle=True)\n",
        "\n",
        "    # Initialize model\n",
        "    model = FFNNClassifier(\n",
        "        input_size,\n",
        "        hidden_sizes=params['hidden_sizes'],\n",
        "        dropout_rate=params['dropout_rate']\n",
        "    )\n",
        "\n",
        "    # Setup training\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=params['learning_rate'],\n",
        "        weight_decay=params['weight_decay']\n",
        "    )\n",
        "\n",
        "    # Training loop with early stopping\n",
        "    model.train()\n",
        "    best_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(30):  # Reduced epochs for grid search\n",
        "        total_loss = 0\n",
        "        for batch_X, batch_y in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "        # Early stopping\n",
        "        if avg_loss < best_loss:\n",
        "            best_loss = avg_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= 5:  # Reduced patience\n",
        "            break\n",
        "\n",
        "    return model, best_loss\n",
        "\n",
        "def evaluate_ffnn_model(model, X_val, y_val):\n",
        "    \"\"\"Evaluate FFNN model and return F1-score\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X_val)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "    y_true = y_val.cpu().numpy()\n",
        "    y_pred = predicted.cpu().numpy()\n",
        "    return f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "def ffnn_grid_search(X_tensor, y_tensor, input_size):\n",
        "    \"\"\"Perform grid search for FFNN hyperparameters\"\"\"\n",
        "    param_grid = create_ffnn_param_grid()\n",
        "\n",
        "    # Split data for validation\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn.metrics import f1_score\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_tensor, y_tensor, test_size=0.2, random_state=42, stratify=y_tensor\n",
        "    )\n",
        "\n",
        "    best_score = 0\n",
        "    best_params = {}\n",
        "    best_model = None\n",
        "\n",
        "    print(\"Starting FFNN Grid Search...\")\n",
        "\n",
        "    # Generate all parameter combinations\n",
        "    combinations = []\n",
        "    for hidden_sizes in param_grid['hidden_sizes']:\n",
        "        for dropout_rate in param_grid['dropout_rate']:\n",
        "            for learning_rate in param_grid['learning_rate']:\n",
        "                for batch_size in param_grid['batch_size']:\n",
        "                    for weight_decay in param_grid['weight_decay']:\n",
        "                        combinations.append({\n",
        "                            'hidden_sizes': hidden_sizes,\n",
        "                            'dropout_rate': dropout_rate,\n",
        "                            'learning_rate': learning_rate,\n",
        "                            'batch_size': batch_size,\n",
        "                            'weight_decay': weight_decay\n",
        "                        })\n",
        "\n",
        "    print(f\"Testing {len(combinations)} combinations...\")\n",
        "\n",
        "    for i, params in enumerate(combinations, 1):\n",
        "        try:\n",
        "            print(f\"Combination {i}/{len(combinations)}: {params}\")\n",
        "\n",
        "            # Train model\n",
        "            model, _ = train_ffnn_model(X_train, y_train, params, input_size)\n",
        "\n",
        "            # Evaluate model\n",
        "            score = evaluate_ffnn_model(model, X_val, y_val)\n",
        "\n",
        "            print(f\"  Validation F1: {score:.4f}\")\n",
        "\n",
        "            # Update best if necessary\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_params = params.copy()\n",
        "                best_model = model.state_dict().copy()\n",
        "                print(f\"  New best! Score: {best_score:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error: {e}\")\n",
        "            continue\n",
        "\n",
        "    return best_params, best_score, best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "047ad227",
      "metadata": {
        "id": "047ad227"
      },
      "source": [
        "## Distillbert helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "768b3af1",
      "metadata": {
        "id": "768b3af1"
      },
      "outputs": [],
      "source": [
        "def create_distilbert_param_grid():\n",
        "    \"\"\"Create parameter grid for DistilBERT\"\"\"\n",
        "    return {\n",
        "        'num_train_epochs': [3],\n",
        "        'per_device_train_batch_size': [16, 32],\n",
        "        'learning_rate': [2e-5, 5e-5],\n",
        "        'weight_decay': [0.01, 0.001],\n",
        "        'warmup_steps': [100, 200]\n",
        "    }\n",
        "\n",
        "def train_distilbert_model(train_dataset, val_dataset, tokenizer, params):\n",
        "    \"\"\"Train a single DistilBERT model with given parameters\"\"\"\n",
        "    # Load model\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\n",
        "        'distilbert-base-uncased',\n",
        "        num_labels=2,\n",
        "        problem_type=\"single_label_classification\"\n",
        "    )\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./trump_distilbert_temp',\n",
        "        num_train_epochs=params['num_train_epochs'],\n",
        "        per_device_train_batch_size=params['per_device_train_batch_size'],\n",
        "        per_device_eval_batch_size=params['per_device_train_batch_size'],\n",
        "        learning_rate=params['learning_rate'],\n",
        "        weight_decay=params['weight_decay'],\n",
        "        warmup_steps=params['warmup_steps'],\n",
        "        logging_steps=50,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=100,\n",
        "        save_strategy=\"no\",  # Don't save during grid search\n",
        "        load_best_model_at_end=False,\n",
        "        remove_unused_columns=False,\n",
        "        push_to_hub=False,\n",
        "        report_to=None,\n",
        "        metric_for_best_model=\"f1\",\n",
        "        greater_is_better=True\n",
        "    )\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  # Reduced patience\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate and return score\n",
        "    eval_results = trainer.evaluate()\n",
        "    return model, eval_results['eval_f1']\n",
        "\n",
        "def distilbert_grid_search(texts, labels, tokenizer):\n",
        "    \"\"\"Perform grid search for DistilBERT hyperparameters\"\"\"\n",
        "    param_grid = create_distilbert_param_grid()\n",
        "\n",
        "    # Split data for validation\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "        texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
        "    )\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = TweetDataset(train_texts, train_labels, tokenizer)\n",
        "    val_dataset = TweetDataset(val_texts, val_labels, tokenizer)\n",
        "\n",
        "    best_score = 0\n",
        "    best_params = {}\n",
        "    best_model = None\n",
        "\n",
        "    print(\"Starting DistilBERT Grid Search...\")\n",
        "\n",
        "    # Generate parameter combinations (simplified)\n",
        "    combinations = []\n",
        "    for epochs in param_grid['num_train_epochs']:\n",
        "        for batch_size in param_grid['per_device_train_batch_size']:\n",
        "            for lr in param_grid['learning_rate']:\n",
        "                for wd in param_grid['weight_decay']:\n",
        "                    for warmup in param_grid['warmup_steps']:\n",
        "                        combinations.append({\n",
        "                            'num_train_epochs': epochs,\n",
        "                            'per_device_train_batch_size': batch_size,\n",
        "                            'learning_rate': lr,\n",
        "                            'weight_decay': wd,\n",
        "                            'warmup_steps': warmup\n",
        "                        })\n",
        "\n",
        "    # Limit combinations for computational efficiency\n",
        "    combinations = combinations[:3]  # Test only first 3 combinations\n",
        "    print(f\"Testing {len(combinations)} combinations...\")\n",
        "\n",
        "    for i, params in enumerate(combinations, 1):\n",
        "        try:\n",
        "            print(f\"Combination {i}/{len(combinations)}: {params}\")\n",
        "\n",
        "            # Train model\n",
        "            model, score = train_distilbert_model(train_dataset, val_dataset, tokenizer, params)\n",
        "\n",
        "            print(f\"  F1 Score: {score:.4f}\")\n",
        "\n",
        "            # Update best if necessary\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_params = params.copy()\n",
        "                best_model = model\n",
        "                print(f\"  New best! Score: {best_score:.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error: {e}\")\n",
        "            continue\n",
        "\n",
        "    return best_params, best_score, best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "QjbwaQOTcXiE",
      "metadata": {
        "id": "QjbwaQOTcXiE"
      },
      "outputs": [],
      "source": [
        "def training_pipeline(alg, train_fn):\n",
        "    \"\"\"Returns a trained model given the specific task and algorithm.\"\"\"\n",
        "\n",
        "    train_clean = preprocess_train_data(train_fn)\n",
        "    # print(train_clean)\n",
        "\n",
        "    # Extract features\n",
        "    train_clean = extract_timestamp_features(train_clean)\n",
        "    train_clean['label'] = train_clean['device'].map({'android': 0, 'iphone': 1})\n",
        "\n",
        "    # Define feature columns\n",
        "    temporal_features = ['hour_of_day', 'day_of_week', 'day_of_month', 'month',\n",
        "                'is_weekend', 'season', 'time_period', 'is_business_hours', 'is_late_night']\n",
        "\n",
        "    if alg == 1:  # Logistic Regression with Grid Search\n",
        "\n",
        "        # Prepare features\n",
        "        X_text = train_clean['processed_tweet']\n",
        "        X_temporal = train_clean[temporal_features]\n",
        "        y = train_clean['label']\n",
        "\n",
        "        # Create and fit TF-IDF vectorizer\n",
        "        tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=2, max_df=0.95)\n",
        "        X_text_tfidf = tfidf.fit_transform(X_text)\n",
        "\n",
        "        # Scale temporal features\n",
        "        scaler = StandardScaler()\n",
        "        X_temp_scaled = scaler.fit_transform(X_temporal)\n",
        "\n",
        "        # Combine features\n",
        "        from scipy.sparse import hstack\n",
        "        X_combined = hstack([X_text_tfidf, X_temp_scaled])\n",
        "\n",
        "        # Grid search for Logistic Regression hyperparameters\n",
        "        param_grid = {\n",
        "            'C': [1.0, 2.0],\n",
        "            'max_iter': [10000],\n",
        "            'solver': ['liblinear', 'lbfgs'],\n",
        "            'penalty': ['l2']\n",
        "        }\n",
        "\n",
        "        # Create LogisticRegression instance\n",
        "        lr = LogisticRegression(random_state=42)\n",
        "\n",
        "        # Perform grid search with cross-validation\n",
        "        print(\"Starting Grid Search for Logistic Regression...\")\n",
        "        grid_search = GridSearchCV(\n",
        "            estimator=lr,\n",
        "            param_grid=param_grid,\n",
        "            cv=3,  # 3-fold cross-validation\n",
        "            scoring='f1',\n",
        "            n_jobs=-1,  # Use all available cores\n",
        "            verbose=1   # Print progress\n",
        "        )\n",
        "\n",
        "        # Fit the grid search\n",
        "        grid_search.fit(X_combined, y)\n",
        "\n",
        "        # Print results\n",
        "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "        # Get the best classifier\n",
        "        best_classifier = grid_search.best_estimator_\n",
        "\n",
        "        # Return model components\n",
        "        return {\n",
        "            'algo_num': 1,\n",
        "            'classifier': best_classifier,\n",
        "            'tfidf': tfidf,\n",
        "            'scaler': scaler,\n",
        "            'temporal_features': temporal_features,\n",
        "            'best_params': grid_search.best_params_,\n",
        "            'cv_score': grid_search.best_score_,\n",
        "            'grid_search': grid_search  # Store the full grid search object if needed\n",
        "        }\n",
        "\n",
        "    elif alg == 2:  # SVM (both linear and nonlinear)\n",
        "\n",
        "        # Prepare features\n",
        "        X_text = train_clean['processed_tweet']\n",
        "        X_temporal = train_clean[temporal_features]\n",
        "        # print(X_temporal)\n",
        "        y = train_clean['label']\n",
        "\n",
        "\n",
        "        # Create and fit TF-IDF vectorizer\n",
        "        tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=10, max_df=0.95)\n",
        "        # print(X_text)\n",
        "        X_text_tfidf = tfidf.fit_transform(X_text)\n",
        "\n",
        "        # Scale temporal features\n",
        "        scaler = StandardScaler()\n",
        "        X_temp_scaled = scaler.fit_transform(X_temporal)\n",
        "\n",
        "        # Combine features\n",
        "        from scipy.sparse import hstack\n",
        "        X_combined = hstack([X_text_tfidf, X_temp_scaled])\n",
        "\n",
        "        # Grid search for best SVM kernel and parameters\n",
        "        param_grid = [\n",
        "            # Linear kernel\n",
        "            {\n",
        "                'kernel': ['linear'],\n",
        "                'C': [0.1, 1.0, 10.0]\n",
        "            },\n",
        "            # RBF (nonlinear) kernel\n",
        "            {\n",
        "                'kernel': ['rbf'],\n",
        "                'C': [0.1, 1.0, 10.0],\n",
        "                'gamma': ['scale', 'auto', 0.001, 0.01]\n",
        "            },\n",
        "            # Polynomial (nonlinear) kernel\n",
        "            {\n",
        "                'kernel': ['poly'],\n",
        "                'C': [0.1, 1.0, 10.0],\n",
        "                'degree': [2, 3],\n",
        "                'gamma': ['scale', 'auto']\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        # Use GridSearchCV to find best parameters\n",
        "        svm = SVC(random_state=42, probability=True)  # probability=True for predict_proba\n",
        "        grid_search = GridSearchCV(\n",
        "            svm,\n",
        "            param_grid,\n",
        "            cv=3,  # 3-fold CV to save time\n",
        "            scoring='f1',\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        print(\"Training SVM with grid search...\")\n",
        "        grid_search.fit(X_combined, y)\n",
        "\n",
        "        print(f\"Best SVM parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "        # Return model components\n",
        "        return {\n",
        "            'algo_num': 2,\n",
        "            'classifier': grid_search.best_estimator_,\n",
        "            'tfidf': tfidf,\n",
        "            'scaler': scaler,\n",
        "            'temporal_features': temporal_features,\n",
        "            'best_params': grid_search.best_params_,\n",
        "            'cv_score': grid_search.best_score_\n",
        "        }\n",
        "\n",
        "    # Add other algorithms here (alg 3-5)\n",
        "    elif alg == 3:  # Feed-Forward Neural Network (FFNN) with Grid Search\n",
        "\n",
        "        # Prepare features (same as before)\n",
        "        X_text = train_clean['processed_tweet']\n",
        "        X_temporal = train_clean[temporal_features]\n",
        "        y = train_clean['label']\n",
        "\n",
        "        # TF-IDF setup (same as before)\n",
        "        valid_texts = [text for text in X_text if text and text.strip() and text != 'empty_tweet']\n",
        "\n",
        "        if len(valid_texts) < 2:\n",
        "            print(f\"Warning: Only {len(valid_texts)} valid texts found. Using minimal TF-IDF settings.\")\n",
        "            tfidf = TfidfVectorizer(max_features=1000, ngram_range=(1, 1), min_df=1, max_df=1.0)\n",
        "        else:\n",
        "            min_df = max(1, min(2, len(valid_texts) // 10))\n",
        "            tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=min_df, max_df=0.95)\n",
        "\n",
        "        try:\n",
        "            X_text_tfidf = tfidf.fit_transform(X_text)\n",
        "        except ValueError as e:\n",
        "            print(f\"TF-IDF failed with error: {e}\")\n",
        "            print(\"Falling back to basic word count...\")\n",
        "            tfidf = TfidfVectorizer(max_features=100, ngram_range=(1, 1), min_df=1, max_df=1.0)\n",
        "            X_text_tfidf = tfidf.fit_transform(X_text)\n",
        "\n",
        "        # Scale temporal features\n",
        "        scaler = StandardScaler()\n",
        "        X_temp_scaled = scaler.fit_transform(X_temporal)\n",
        "\n",
        "        # Combine features and convert to tensors\n",
        "        from scipy.sparse import hstack\n",
        "        X_combined = hstack([X_text_tfidf, X_temp_scaled]).toarray()\n",
        "        X_tensor = torch.FloatTensor(X_combined)\n",
        "        y_tensor = torch.LongTensor(y.values)\n",
        "        input_size = X_combined.shape[1]\n",
        "\n",
        "        # Perform grid search\n",
        "        best_params, best_score, best_model_state = ffnn_grid_search(X_tensor, y_tensor, input_size)\n",
        "\n",
        "        print(f\"\\nGrid Search Complete!\")\n",
        "        print(f\"Best parameters: {best_params}\")\n",
        "        print(f\"Best validation score: {best_score:.4f}\")\n",
        "\n",
        "        # Train final model with best parameters on full dataset\n",
        "        print(\"Training final model...\")\n",
        "        dataset = TensorDataset(X_tensor, y_tensor)\n",
        "        dataloader = DataLoader(dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
        "\n",
        "        final_model = FFNNClassifier(\n",
        "            input_size,\n",
        "            hidden_sizes=best_params['hidden_sizes'],\n",
        "            dropout_rate=best_params['dropout_rate']\n",
        "        )\n",
        "\n",
        "        # Load best weights if available\n",
        "        if best_model_state is not None:\n",
        "            try:\n",
        "                final_model.load_state_dict(best_model_state)\n",
        "            except:\n",
        "                print(\"Could not load best weights, training from scratch...\")\n",
        "\n",
        "        # Final training (same training loop as before but with best params)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(\n",
        "            final_model.parameters(),\n",
        "            lr=best_params['learning_rate'],\n",
        "            weight_decay=best_params['weight_decay']\n",
        "        )\n",
        "\n",
        "        final_model.train()\n",
        "        best_loss = float('inf')\n",
        "        patience_counter = 0\n",
        "\n",
        "        print(\"Final training...\")\n",
        "        for epoch in range(100):\n",
        "            total_loss = 0\n",
        "            for batch_X, batch_y in dataloader:\n",
        "                optimizer.zero_grad()\n",
        "                outputs = final_model(batch_X)\n",
        "                loss = criterion(outputs, batch_y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            avg_loss = total_loss / len(dataloader)\n",
        "\n",
        "            if avg_loss < best_loss:\n",
        "                best_loss = avg_loss\n",
        "                patience_counter = 0\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            if patience_counter >= 10:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "            if (epoch + 1) % 20 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/100], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        final_model.eval()\n",
        "\n",
        "        # Return model components\n",
        "        return {\n",
        "            'algo_num': 3,\n",
        "            'model': final_model,\n",
        "            'tfidf': tfidf,\n",
        "            'scaler': scaler,\n",
        "            'temporal_features': temporal_features,\n",
        "            'best_params': best_params,\n",
        "            'cv_score': best_score\n",
        "        }\n",
        "\n",
        "    # Add other algorithms here (alg 4-5)\n",
        "    elif alg == 4:  # Random Forest with Rich Feature Engineering\n",
        "\n",
        "        # Extract rich stylometric features\n",
        "        rich_features = extract_rich_features(train_clean)\n",
        "\n",
        "        # Prepare text features (simplified TF-IDF for speed)\n",
        "        X_text = train_clean['processed_tweet']\n",
        "\n",
        "        # Adaptive TF-IDF settings\n",
        "        valid_texts = [text for text in X_text if text and text.strip() and text != 'empty_tweet']\n",
        "        min_df = max(1, min(3, len(valid_texts) // 20))\n",
        "\n",
        "        try:\n",
        "            tfidf = TfidfVectorizer(max_features=2000, ngram_range=(1, 2), min_df=min_df, max_df=0.9)\n",
        "            X_text_tfidf = tfidf.fit_transform(X_text)\n",
        "        except ValueError:\n",
        "            tfidf = TfidfVectorizer(max_features=500, ngram_range=(1, 1), min_df=1, max_df=1.0)\n",
        "            X_text_tfidf = tfidf.fit_transform(X_text)\n",
        "\n",
        "        # Prepare temporal and rich features\n",
        "        X_temporal = train_clean[temporal_features]\n",
        "        X_rich = rich_features\n",
        "\n",
        "        # Scale features\n",
        "        scaler_temporal = StandardScaler()\n",
        "        scaler_rich = StandardScaler()\n",
        "\n",
        "        X_temp_scaled = scaler_temporal.fit_transform(X_temporal)\n",
        "        X_rich_scaled = scaler_rich.fit_transform(X_rich)\n",
        "\n",
        "        # Combine all features\n",
        "        from scipy.sparse import hstack, csr_matrix\n",
        "        X_combined = hstack([\n",
        "            X_text_tfidf,\n",
        "            csr_matrix(X_temp_scaled),\n",
        "            csr_matrix(X_rich_scaled)\n",
        "        ])\n",
        "\n",
        "        y = train_clean['label']\n",
        "\n",
        "        # Grid search for Random Forest\n",
        "        param_grid = {\n",
        "            'n_estimators': [100, 200],\n",
        "            'max_depth': [10, 20, None],\n",
        "            'min_samples_split': [2],\n",
        "            'min_samples_leaf': [1, 2],\n",
        "            'max_features': ['sqrt', None]\n",
        "            # 'n_estimators': [100],\n",
        "            # 'max_depth': [10],\n",
        "            # 'min_samples_split': [5],\n",
        "            # 'min_samples_leaf': [2],\n",
        "            # 'max_features': ['sqrt', 'log2', None]\n",
        "        }\n",
        "\n",
        "        rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "        grid_search = GridSearchCV(\n",
        "            rf,\n",
        "            param_grid,\n",
        "            cv=3,\n",
        "            scoring='f1',\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        print(\"Training Random Forest with rich features...\")\n",
        "        grid_search.fit(X_combined, y)\n",
        "\n",
        "        print(f\"Best RF parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "        # Get feature importance\n",
        "        feature_names = (\n",
        "            [f'tfidf_{i}' for i in range(X_text_tfidf.shape[1])] +\n",
        "            temporal_features +\n",
        "            list(rich_features.columns)\n",
        "        )\n",
        "\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'feature': feature_names,\n",
        "            'importance': grid_search.best_estimator_.feature_importances_\n",
        "        }).sort_values('importance', ascending=False)\n",
        "\n",
        "        print(\"\\nTop 20 Most Important Features:\")\n",
        "        print(feature_importance.head(20))\n",
        "\n",
        "        # Return model components\n",
        "        return {\n",
        "            'algo_num': 4,\n",
        "            'classifier': grid_search.best_estimator_,\n",
        "            'tfidf': tfidf,\n",
        "            'scaler_temporal': scaler_temporal,\n",
        "            'scaler_rich': scaler_rich,\n",
        "            'temporal_features': temporal_features,\n",
        "            'rich_feature_names': list(rich_features.columns),\n",
        "            'best_params': grid_search.best_params_,\n",
        "            'cv_score': grid_search.best_score_,\n",
        "            'feature_importance': feature_importance,\n",
        "            'extract_rich_features': extract_rich_features  # Store the function for prediction\n",
        "        }\n",
        "\n",
        "    elif alg == 5:  # DistilBERT Transformer with Grid Search\n",
        "\n",
        "        print(\"Loading DistilBERT tokenizer...\")\n",
        "        tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "        # Prepare texts with light preprocessing\n",
        "        texts = train_clean['tweet'].apply(light_preprocess_for_transformer).tolist()\n",
        "        labels = train_clean['label'].tolist()\n",
        "\n",
        "        # Perform grid search\n",
        "        best_params, best_score, best_model = distilbert_grid_search(texts, labels, tokenizer)\n",
        "\n",
        "        print(f\"\\nGrid Search Complete!\")\n",
        "        print(f\"Best parameters: {best_params}\")\n",
        "        print(f\"Best validation score: {best_score:.4f}\")\n",
        "\n",
        "        # Train final model with best parameters on full dataset\n",
        "        print(\"Training final model with best parameters...\")\n",
        "\n",
        "        # Split data for final training\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "            texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
        "        )\n",
        "\n",
        "        # Create datasets\n",
        "        train_dataset = TweetDataset(train_texts, train_labels, tokenizer)\n",
        "        val_dataset = TweetDataset(val_texts, val_labels, tokenizer)\n",
        "\n",
        "        # Final model with best parameters\n",
        "        final_model = DistilBertForSequenceClassification.from_pretrained(\n",
        "            'distilbert-base-uncased',\n",
        "            num_labels=2,\n",
        "            problem_type=\"single_label_classification\"\n",
        "        )\n",
        "\n",
        "        # Final training arguments\n",
        "        final_training_args = TrainingArguments(\n",
        "            output_dir='./trump_distilbert_final',\n",
        "            num_train_epochs=best_params['num_train_epochs'],\n",
        "            per_device_train_batch_size=best_params['per_device_train_batch_size'],\n",
        "            per_device_eval_batch_size=best_params['per_device_train_batch_size'],\n",
        "            learning_rate=best_params['learning_rate'],\n",
        "            weight_decay=best_params['weight_decay'],\n",
        "            warmup_steps=best_params['warmup_steps'],\n",
        "            logging_dir='./logs',\n",
        "            logging_steps=10,\n",
        "            eval_strategy=\"steps\",\n",
        "            eval_steps=50,\n",
        "            save_strategy=\"steps\",\n",
        "            save_steps=50,\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"f1\",\n",
        "            greater_is_better=True,\n",
        "            save_total_limit=2,\n",
        "            remove_unused_columns=False,\n",
        "            push_to_hub=False,\n",
        "            report_to=None,\n",
        "        )\n",
        "\n",
        "        # Final trainer\n",
        "        final_trainer = Trainer(\n",
        "            model=final_model,\n",
        "            args=final_training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            compute_metrics=compute_metrics,\n",
        "            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        "        )\n",
        "\n",
        "        print(\"Final training...\")\n",
        "        final_trainer.train()\n",
        "\n",
        "        # Final evaluation\n",
        "        eval_results = final_trainer.evaluate()\n",
        "        print(f\"Final DistilBERT Results: {eval_results}\")\n",
        "\n",
        "        # Return model components\n",
        "        return {\n",
        "            'algo_num': 5,\n",
        "            'model': final_model,\n",
        "            'tokenizer': tokenizer,\n",
        "            'trainer': final_trainer,\n",
        "            'light_preprocess': light_preprocess_for_transformer,\n",
        "            'best_params': best_params,\n",
        "            'cv_score': best_score,\n",
        "            'eval_results': eval_results\n",
        "        }\n",
        "    else:\n",
        "        raise NotImplementedError(f\"Algorithm {alg} not implemented yet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "274b23af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "274b23af",
        "outputId": "11620073-832a-4db8-b290-f2b527e5b228"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training pipeline for algorithm: logistic regression\n",
            "Shape of the original dataset: (3515, 5)\n",
            "Starting Grid Search for Logistic Regression...\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-21-3017618251>:66: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(mod_value, inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'C': 2.0, 'max_iter': 10000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "Best cross-validation score: 0.6855\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nTraining pipeline for algorithm: logistic regression\")\n",
        "lr_model = training_pipeline(1, 'trump_train.tsv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dca845f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dca845f5",
        "outputId": "f01fb47e-ca8c-49e5-eb7b-b5a49573d285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training pipeline for algorithm: SVM\n",
            "Shape of the original dataset: (3515, 5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-21-3017618251>:66: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(mod_value, inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training SVM with grid search...\n",
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
            "Best SVM parameters: {'C': 1.0, 'kernel': 'linear'}\n",
            "Best cross-validation score: 0.6879\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nTraining pipeline for algorithm: SVM\")\n",
        "svm_model = training_pipeline(2, 'trump_train.tsv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "44a9852c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44a9852c",
        "outputId": "391d02cb-e915-4763-b7ad-e54ff0881dc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training pipeline for algorithm: FFNN\n",
            "Shape of the original dataset: (3515, 5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-3017618251>:66: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(mod_value, inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting FFNN Grid Search...\n",
            "Testing 12 combinations...\n",
            "Combination 1/12: {'hidden_sizes': [128], 'dropout_rate': 0.2, 'learning_rate': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n",
            "  Validation F1: 0.7731\n",
            "  New best! Score: 0.7731\n",
            "Combination 2/12: {'hidden_sizes': [128], 'dropout_rate': 0.2, 'learning_rate': 0.01, 'batch_size': 32, 'weight_decay': 0.0001}\n",
            "  Validation F1: 0.7691\n",
            "Combination 3/12: {'hidden_sizes': [128], 'dropout_rate': 0.5, 'learning_rate': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n",
            "  Validation F1: 0.7849\n",
            "  New best! Score: 0.7849\n",
            "Combination 4/12: {'hidden_sizes': [128], 'dropout_rate': 0.5, 'learning_rate': 0.01, 'batch_size': 32, 'weight_decay': 0.0001}\n",
            "  Validation F1: 0.7827\n",
            "Combination 5/12: {'hidden_sizes': [256, 128], 'dropout_rate': 0.2, 'learning_rate': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n",
            "  Validation F1: 0.7722\n",
            "Combination 6/12: {'hidden_sizes': [256, 128], 'dropout_rate': 0.2, 'learning_rate': 0.01, 'batch_size': 32, 'weight_decay': 0.0001}\n",
            "  Validation F1: 0.7777\n",
            "Combination 7/12: {'hidden_sizes': [256, 128], 'dropout_rate': 0.5, 'learning_rate': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n",
            "  Validation F1: 0.7826\n",
            "Combination 8/12: {'hidden_sizes': [256, 128], 'dropout_rate': 0.5, 'learning_rate': 0.01, 'batch_size': 32, 'weight_decay': 0.0001}\n",
            "  Validation F1: 0.7893\n",
            "  New best! Score: 0.7893\n",
            "Combination 9/12: {'hidden_sizes': [256, 128], 'dropout_rate': 0.2, 'learning_rate': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n",
            "  Validation F1: 0.7754\n",
            "Combination 10/12: {'hidden_sizes': [256, 128], 'dropout_rate': 0.2, 'learning_rate': 0.01, 'batch_size': 32, 'weight_decay': 0.0001}\n",
            "  Validation F1: 0.7862\n",
            "Combination 11/12: {'hidden_sizes': [256, 128], 'dropout_rate': 0.5, 'learning_rate': 0.001, 'batch_size': 32, 'weight_decay': 0.0001}\n",
            "  Validation F1: 0.7847\n",
            "Combination 12/12: {'hidden_sizes': [256, 128], 'dropout_rate': 0.5, 'learning_rate': 0.01, 'batch_size': 32, 'weight_decay': 0.0001}\n",
            "  Validation F1: 0.7796\n",
            "\n",
            "Grid Search Complete!\n",
            "Best parameters: {'hidden_sizes': [256, 128], 'dropout_rate': 0.5, 'learning_rate': 0.01, 'batch_size': 32, 'weight_decay': 0.0001}\n",
            "Best validation score: 0.7893\n",
            "Training final model...\n",
            "Final training...\n",
            "Epoch [20/100], Loss: 0.1514\n",
            "Early stopping at epoch 26\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nTraining pipeline for algorithm: FFNN\")\n",
        "FFNN_model = training_pipeline(3, 'trump_train.tsv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4aacd06",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4aacd06",
        "outputId": "ba9ee45c-df42-4867-cd7c-5f4447f41d16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training pipeline for algorithm: Random Forest with Rich Features\n",
            "Shape of the original dataset: (3515, 5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-21-3017618251>:66: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(mod_value, inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Random Forest with rich features...\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Best RF parameters: {'max_depth': None, 'max_features': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Best cross-validation score: 0.8093\n",
            "\n",
            "Top 20 Most Important Features:\n",
            "                  feature  importance\n",
            "2026            url_count    0.352875\n",
            "2023          quote_count    0.119116\n",
            "2000          hour_of_day    0.079986\n",
            "2024        mention_count    0.045704\n",
            "2009          text_length    0.035609\n",
            "2030  starts_with_capital    0.028316\n",
            "2002         day_of_month    0.016055\n",
            "2001          day_of_week    0.015354\n",
            "2013      uppercase_ratio    0.014983\n",
            "2016    punctuation_ratio    0.010591\n",
            "2003                month    0.009519\n",
            "2025        hashtag_count    0.009412\n",
            "2015          space_ratio    0.007871\n",
            "2022           dash_count    0.007293\n",
            "2011      avg_word_length    0.007171\n",
            "2029     title_case_words    0.007005\n",
            "2010           word_count    0.006879\n",
            "2006          time_period    0.006166\n",
            "2017    exclamation_count    0.005568\n",
            "2005               season    0.004000\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\nTraining pipeline for algorithm: Random Forest with Rich Features\")\n",
        "rf_model = training_pipeline(4, 'trump_train.tsv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "419dbaaa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8fd2700f302b4c82b323c266f5e126a3",
            "3cb21ac81a0b4bada1ddea6f68f3ed79",
            "6921d34827b847a8867c3e7fa2105ffb",
            "695be64fc1204bf39cc2847f505a6667",
            "df7697041855484f8eb0f567ffa4c7bd",
            "1d1c6dc3f27c4a819f84531ef1f3b60c",
            "ef8d6f08cb134b0c941b735ca8e95752",
            "bfab020a77e04efe8136bed7febb9f42",
            "826b7474506e459d91a5473623c9597e",
            "5d43f49cc0b941c8988264c583a25be9",
            "00ad7be748b2416fa0215549e0855ebe",
            "50a9af899cd141dabe42f50e2523bd90",
            "4f029fb90af04d1397991106f861dc23",
            "901d90f4be8446b3ad05826f81586f82",
            "9a33a68c5b9c417c8312ac5ae7f128a6",
            "194deb9f928a41c9a5914c3d32215a84",
            "5c4348a97d6642f2b98ffc77657b984c",
            "f577e490cdb9422a8b16db19148e186c",
            "b839837cde3c46b3813a9691217288fb",
            "55f57d49638349ef975e254c1b5ae601",
            "1a8ab8027fcc4d30ba332bfd53a71af3",
            "7ca7c7f30ac549c9a8c78ec019880f11",
            "d05ef473472d451e85b5888d67145670",
            "69a0b69e99bd4332ad9088ae56cf4c3a",
            "e07b81a4d10c4fbca6b2b6fc91f352a5",
            "95f34338c88047a383af29771d94d621",
            "2f8e1284cf064ff7983cef37265a82cd",
            "576bb5ece5a74b099cb22a02a73cab01",
            "4a13fffd5d8a4e878765dcb2eca6b2f5",
            "f8871bc472004a61919aa4162b5d3a92",
            "ff0dbacd05bf40b9bf0e91030ca0942e",
            "316a6ef6eeb141298a4275f52777c5fd",
            "b714e757297f4ec29baf09d051c64f5b",
            "4f05783446944bdb91a9d25db73e34cd",
            "1ed34168f8e24861a89ab3ab47550695",
            "f1366898c1804be08b804d46e679d6e8",
            "d4a80a6fac034d42b468c38f81f81205",
            "d674af637bfb4cf0b1b03109a762bd11",
            "297e2dcacb7d416ebc48aeb4de11dc61",
            "0246f5ae5cc1413f92d51962fd475562",
            "fa812637134242c5bab375c7fdb7a298",
            "4d0ace50563547f08e9477bb036c0fe5",
            "15b64fc8cc3b481da0f2a2f1e3a4dd50",
            "1c6b31675aa2404791e1049536697fc9",
            "6baa64eafe994b0590454f912666e6bb",
            "ce8aa99d6c1b4e07a0513eb4b1aa4e1b",
            "85f23048627345f5a037e7531bc69a3f",
            "9ce77069b1ea47dabf5e9cb22c163b47",
            "d8e9252678c24e6e822a848efd98e1ff",
            "587b4919427e4a1d836a0bd9b92dabb5",
            "f51661ccc63a4d59b61c955a4621a2e0",
            "13fca8733cd44a6887226d74d3a6b7c5",
            "27d874f6f9b44bc2864a4eba1b9447d0",
            "6e558f3473eb4705914b1dc2ba73dfab",
            "c4c097c0f1854c21b76152edca5503b4"
          ]
        },
        "id": "419dbaaa",
        "outputId": "af997b38-fea3-4430-88d6-a2a3d14bbf2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training pipeline for algorithm: Bert\n",
            "Shape of the original dataset: (3515, 5)\n",
            "Loading DistilBERT tokenizer...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fd2700f302b4c82b323c266f5e126a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50a9af899cd141dabe42f50e2523bd90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d05ef473472d451e85b5888d67145670",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f05783446944bdb91a9d25db73e34cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting DistilBERT Grid Search...\n",
            "Testing 3 combinations...\n",
            "Combination 1/3: {'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'warmup_steps': 100}\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6baa64eafe994b0590454f912666e6bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='528' max='528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [528/528 00:55, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.399400</td>\n",
              "      <td>0.345648</td>\n",
              "      <td>0.871977</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.982143</td>\n",
              "      <td>0.654762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.284700</td>\n",
              "      <td>0.280947</td>\n",
              "      <td>0.887624</td>\n",
              "      <td>0.820862</td>\n",
              "      <td>0.957672</td>\n",
              "      <td>0.718254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.243000</td>\n",
              "      <td>0.290146</td>\n",
              "      <td>0.887624</td>\n",
              "      <td>0.816705</td>\n",
              "      <td>0.983240</td>\n",
              "      <td>0.698413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.154900</td>\n",
              "      <td>0.266533</td>\n",
              "      <td>0.897582</td>\n",
              "      <td>0.841410</td>\n",
              "      <td>0.945545</td>\n",
              "      <td>0.757937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.166000</td>\n",
              "      <td>0.251703</td>\n",
              "      <td>0.899004</td>\n",
              "      <td>0.846652</td>\n",
              "      <td>0.928910</td>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [44/44 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  F1 Score: 0.8498\n",
            "  New best! Score: 0.8498\n",
            "Combination 2/3: {'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'warmup_steps': 200}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='528' max='528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [528/528 00:56, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.501100</td>\n",
              "      <td>0.396815</td>\n",
              "      <td>0.856330</td>\n",
              "      <td>0.753056</td>\n",
              "      <td>0.980892</td>\n",
              "      <td>0.611111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.307900</td>\n",
              "      <td>0.310123</td>\n",
              "      <td>0.871977</td>\n",
              "      <td>0.789720</td>\n",
              "      <td>0.960227</td>\n",
              "      <td>0.670635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.254800</td>\n",
              "      <td>0.323940</td>\n",
              "      <td>0.886202</td>\n",
              "      <td>0.812207</td>\n",
              "      <td>0.994253</td>\n",
              "      <td>0.686508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.171100</td>\n",
              "      <td>0.265330</td>\n",
              "      <td>0.900427</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.166600</td>\n",
              "      <td>0.254367</td>\n",
              "      <td>0.904694</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.926267</td>\n",
              "      <td>0.797619</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [44/44 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  F1 Score: 0.8620\n",
            "  New best! Score: 0.8620\n",
            "Combination 3/3: {'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.001, 'warmup_steps': 100}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "Using EarlyStoppingCallback without load_best_model_at_end=True. Once training is finished, the best model will not be loaded automatically.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='528' max='528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [528/528 00:56, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.411500</td>\n",
              "      <td>0.350422</td>\n",
              "      <td>0.876245</td>\n",
              "      <td>0.792363</td>\n",
              "      <td>0.994012</td>\n",
              "      <td>0.658730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.285600</td>\n",
              "      <td>0.295550</td>\n",
              "      <td>0.881935</td>\n",
              "      <td>0.808314</td>\n",
              "      <td>0.966851</td>\n",
              "      <td>0.694444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.243600</td>\n",
              "      <td>0.307157</td>\n",
              "      <td>0.889047</td>\n",
              "      <td>0.819444</td>\n",
              "      <td>0.983333</td>\n",
              "      <td>0.702381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.158800</td>\n",
              "      <td>0.278361</td>\n",
              "      <td>0.899004</td>\n",
              "      <td>0.846652</td>\n",
              "      <td>0.928910</td>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.169000</td>\n",
              "      <td>0.279831</td>\n",
              "      <td>0.897582</td>\n",
              "      <td>0.842795</td>\n",
              "      <td>0.936893</td>\n",
              "      <td>0.765873</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [44/44 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  F1 Score: 0.8405\n",
            "\n",
            "Grid Search Complete!\n",
            "Best parameters: {'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'warmup_steps': 200}\n",
            "Best validation score: 0.8620\n",
            "Training final model with best parameters...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final training...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='528' max='528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [528/528 01:17, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.621800</td>\n",
              "      <td>0.612004</td>\n",
              "      <td>0.647226</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.015873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.348500</td>\n",
              "      <td>0.396815</td>\n",
              "      <td>0.856330</td>\n",
              "      <td>0.753056</td>\n",
              "      <td>0.980892</td>\n",
              "      <td>0.611111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.351900</td>\n",
              "      <td>0.328484</td>\n",
              "      <td>0.867710</td>\n",
              "      <td>0.781176</td>\n",
              "      <td>0.959538</td>\n",
              "      <td>0.658730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.409900</td>\n",
              "      <td>0.310123</td>\n",
              "      <td>0.871977</td>\n",
              "      <td>0.789720</td>\n",
              "      <td>0.960227</td>\n",
              "      <td>0.670635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.325500</td>\n",
              "      <td>0.273718</td>\n",
              "      <td>0.889047</td>\n",
              "      <td>0.828194</td>\n",
              "      <td>0.930693</td>\n",
              "      <td>0.746032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.135400</td>\n",
              "      <td>0.323940</td>\n",
              "      <td>0.886202</td>\n",
              "      <td>0.812207</td>\n",
              "      <td>0.994253</td>\n",
              "      <td>0.686508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.209800</td>\n",
              "      <td>0.286025</td>\n",
              "      <td>0.889047</td>\n",
              "      <td>0.828947</td>\n",
              "      <td>0.926471</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.220800</td>\n",
              "      <td>0.265330</td>\n",
              "      <td>0.900427</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>0.777778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.171600</td>\n",
              "      <td>0.253557</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>0.847107</td>\n",
              "      <td>0.883621</td>\n",
              "      <td>0.813492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.135200</td>\n",
              "      <td>0.254367</td>\n",
              "      <td>0.904694</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.926267</td>\n",
              "      <td>0.797619</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='44' max='44' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [44/44 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final DistilBERT Results: {'eval_loss': 0.25436684489250183, 'eval_accuracy': 0.9046941678520626, 'eval_f1': 0.8571428571428571, 'eval_precision': 0.9262672811059908, 'eval_recall': 0.7976190476190477, 'eval_runtime': 1.3365, 'eval_samples_per_second': 526.016, 'eval_steps_per_second': 32.923, 'epoch': 3.0}\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(f\"\\nTraining pipeline for algorithm: Bert\")\n",
        "Bert_model = training_pipeline(5, 'trump_train.tsv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91a13219",
      "metadata": {
        "id": "91a13219"
      },
      "outputs": [],
      "source": [
        "def retrain_best_model(train_fn):\n",
        "    \"\"\"\n",
        "    Retrain DistilBERT model with the best hyperparameters found from grid search.\n",
        "    Trains on the full dataset without validation split or evaluation.\n",
        "\n",
        "    Args:\n",
        "        train_fn: Path to training file\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with trained model components\n",
        "    \"\"\"\n",
        "\n",
        "    # Hardcoded best parameters from grid search\n",
        "    best_params = {\n",
        "        'num_train_epochs': 3,\n",
        "        'per_device_train_batch_size': 16,\n",
        "        'learning_rate': 2e-05,\n",
        "        'weight_decay': 0.01,\n",
        "        'warmup_steps': 200\n",
        "    }\n",
        "\n",
        "    print(\"Starting DistilBERT retraining with best parameters...\")\n",
        "    print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "    # Preprocess training data\n",
        "    train_clean = preprocess_train_data(train_fn)\n",
        "    train_clean = extract_timestamp_features(train_clean)\n",
        "    train_clean['label'] = train_clean['device'].map({'android': 0, 'iphone': 1})\n",
        "\n",
        "    # Load tokenizer\n",
        "    print(\"Loading DistilBERT tokenizer...\")\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "    # Prepare texts with light preprocessing\n",
        "    texts = train_clean['tweet'].apply(light_preprocess_for_transformer).tolist()\n",
        "    labels = train_clean['label'].tolist()\n",
        "\n",
        "    # Create dataset for full training data\n",
        "    print(\"Creating training dataset...\")\n",
        "    train_dataset = TweetDataset(texts, labels, tokenizer)\n",
        "\n",
        "    # Initialize model with best parameters\n",
        "    print(\"Initializing DistilBERT model...\")\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(\n",
        "        'distilbert-base-uncased',\n",
        "        num_labels=2,\n",
        "        problem_type=\"single_label_classification\"\n",
        "    )\n",
        "\n",
        "    # Training arguments with best parameters\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir='./trump_distilbert_retrained',\n",
        "        num_train_epochs=best_params['num_train_epochs'],\n",
        "        per_device_train_batch_size=best_params['per_device_train_batch_size'],\n",
        "        per_device_eval_batch_size=best_params['per_device_train_batch_size'],\n",
        "        learning_rate=best_params['learning_rate'],\n",
        "        weight_decay=best_params['weight_decay'],\n",
        "        warmup_steps=best_params['warmup_steps'],\n",
        "        logging_dir='./logs_retrained',\n",
        "        logging_steps=10,\n",
        "        save_strategy=\"no\",  # Disable saving to avoid version conflicts\n",
        "        remove_unused_columns=False,\n",
        "        push_to_hub=False,\n",
        "        report_to=None,\n",
        "    )\n",
        "\n",
        "    # Initialize trainer (no validation dataset)\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        # No eval_dataset, compute_metrics, or callbacks\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    print(\"Training DistilBERT with best parameters...\")\n",
        "    trainer.train()\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "\n",
        "    # Return model components\n",
        "    return {\n",
        "        'algo_num': 5,\n",
        "        'model': model,\n",
        "        'tokenizer': tokenizer,\n",
        "        'trainer': trainer,\n",
        "        'light_preprocess': light_preprocess_for_transformer,\n",
        "        'best_params': best_params\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6aee0cb3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6aee0cb3",
        "outputId": "d4c9c6b0-1137-4748-fbcd-74a61bf32d8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting DistilBERT retraining with best parameters...\n",
            "Best parameters: {'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'warmup_steps': 200}\n",
            "Shape of the original dataset: (3515, 5)\n",
            "Loading DistilBERT tokenizer...\n",
            "Creating training dataset...\n",
            "Initializing DistilBERT model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training DistilBERT with best parameters...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='660' max='660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [660/660 01:01, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.686900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.685200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.662500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.663900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.631200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.649900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.533400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.501200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.480400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.400900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.373000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.272000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.266900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.309800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.259000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.341800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.287500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.280700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.331700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.240900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.265900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.230900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.254400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.366500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.214400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.396200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.243900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.301800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.324200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.267900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.290500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.237700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.245100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.171700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.371300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.211100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.214400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.179200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.173400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.137300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.206700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>0.215300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>0.224800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.180200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.093500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.182800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.186000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>0.125300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.163400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>510</td>\n",
              "      <td>0.232400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>520</td>\n",
              "      <td>0.201300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>530</td>\n",
              "      <td>0.182500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>540</td>\n",
              "      <td>0.122700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.229700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>560</td>\n",
              "      <td>0.120300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>570</td>\n",
              "      <td>0.176300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>580</td>\n",
              "      <td>0.138700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>590</td>\n",
              "      <td>0.220300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.119300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>610</td>\n",
              "      <td>0.102400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>620</td>\n",
              "      <td>0.219800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>630</td>\n",
              "      <td>0.116000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>640</td>\n",
              "      <td>0.144300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.060200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>660</td>\n",
              "      <td>0.190300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training completed!\n"
          ]
        }
      ],
      "source": [
        "best_model = retrain_best_model('trump_train.tsv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31ba308e",
      "metadata": {
        "id": "31ba308e"
      },
      "source": [
        "## Prediction Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eed22a30",
      "metadata": {
        "id": "eed22a30"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import hstack\n",
        "\n",
        "def predict(m, fn):\n",
        "    \"\"\" Returns a list of 0s and 1s, corresponding to the lines in the specified file.\n",
        "\n",
        "        Args:\n",
        "        m: the trained model to be used.\n",
        "        fn: the full path to a file in the same format as the test set we have proveded.\n",
        "    \"\"\"\n",
        "    # Load test data\n",
        "    cols = ['user_handle','tweet','timestamp']\n",
        "    test_df = pd.read_csv(fn, sep=\"\\t\", header=None, names=cols, quoting=3,index_col=False)\n",
        "\n",
        "    # Extract timestamp features\n",
        "    test_clean = extract_timestamp_features(test_df)\n",
        "\n",
        "    # Preprocess text\n",
        "    test_clean['processed_tweet'] = test_clean['tweet'].apply(preprocess_text)\n",
        "\n",
        "    # Prepare features\n",
        "    X_text_test = test_clean['processed_tweet']\n",
        "        # do nothing if temporal features are not present\n",
        "\n",
        "    # print(test_df.head())\n",
        "\n",
        "    if m['algo_num'] == 1:\n",
        "        X_temporal_test = test_clean[m['temporal_features']]\n",
        "\n",
        "        # Transform features using fitted transformers\n",
        "        X_text_tfidf_test = m['tfidf'].transform(X_text_test)\n",
        "        X_temp_scaled_test = m['scaler'].transform(X_temporal_test)\n",
        "\n",
        "        # Combine features\n",
        "        from scipy.sparse import hstack\n",
        "        X_combined_test = hstack([X_text_tfidf_test, X_temp_scaled_test])\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = m['classifier'].predict(X_combined_test)\n",
        "\n",
        "        return predictions.tolist()\n",
        "    elif m['algo_num'] == 2:\n",
        "        X_temporal_test = test_clean[m['temporal_features']]\n",
        "\n",
        "        # Transform features using fitted transformers\n",
        "        X_text_tfidf_test = m['tfidf'].transform(X_text_test)\n",
        "        X_temp_scaled_test = m['scaler'].transform(X_temporal_test)\n",
        "\n",
        "        # Combine features\n",
        "        from scipy.sparse import hstack\n",
        "        X_combined_test = hstack([X_text_tfidf_test, X_temp_scaled_test])\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = m['classifier'].predict(X_combined_test)\n",
        "\n",
        "        return predictions.tolist()\n",
        "    elif m['algo_num'] == 3:  # FFNN\n",
        "        import torch\n",
        "        X_temporal_test = test_clean[m['temporal_features']]\n",
        "\n",
        "\n",
        "        # Transform features using fitted transformers\n",
        "        X_text_tfidf_test = m['tfidf'].transform(X_text_test)\n",
        "        X_temp_scaled_test = m['scaler'].transform(X_temporal_test)\n",
        "\n",
        "        # Combine features and convert to dense\n",
        "        X_combined_test = hstack([X_text_tfidf_test, X_temp_scaled_test]).toarray()\n",
        "\n",
        "        # Convert to PyTorch tensor\n",
        "        X_tensor_test = torch.FloatTensor(X_combined_test)\n",
        "\n",
        "        # Set model to evaluation mode\n",
        "        m['model'].eval()\n",
        "\n",
        "        # Make predictions\n",
        "        with torch.no_grad():\n",
        "            outputs = m['model'](X_tensor_test)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "        return predictions.numpy().tolist()\n",
        "    elif m['algo_num'] == 4:  # Random Forest\n",
        "        # Transform features using fitted transformers\n",
        "        X_temporal_test = test_clean[m['temporal_features']]\n",
        "\n",
        "        X_text_tfidf_test = m['tfidf'].transform(X_text_test)\n",
        "        X_temp_scaled_test = m['scaler_temporal'].transform(X_temporal_test)\n",
        "\n",
        "        # Extract rich features for test data\n",
        "        rich_features_test = m['extract_rich_features'](test_clean)\n",
        "        X_rich_scaled_test = m['scaler_rich'].transform(rich_features_test)\n",
        "\n",
        "        # Combine all features\n",
        "        from scipy.sparse import hstack, csr_matrix\n",
        "        X_combined_test = hstack([\n",
        "            X_text_tfidf_test,\n",
        "            csr_matrix(X_temp_scaled_test),\n",
        "            csr_matrix(X_rich_scaled_test)\n",
        "        ])\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = m['classifier'].predict(X_combined_test)\n",
        "        return predictions.tolist()\n",
        "    elif m['algo_num'] == 5:  # DistilBERT\n",
        "        import torch\n",
        "\n",
        "        # Select device\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Load model and tokenizer\n",
        "        model = m['model'].to(device)\n",
        "        tokenizer = m['tokenizer']\n",
        "\n",
        "        # Preprocess raw tweets for transformer\n",
        "        test_texts = test_df['tweet'].apply(m['light_preprocess']).tolist()\n",
        "\n",
        "        model.eval()\n",
        "        predictions = []\n",
        "        batch_size = 16  # adjust as needed\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, len(test_texts), batch_size):\n",
        "                batch_texts = test_texts[i:i + batch_size]\n",
        "\n",
        "                # Tokenize and move inputs to device\n",
        "                encodings = tokenizer(\n",
        "                    batch_texts,\n",
        "                    truncation=True,\n",
        "                    padding=True,\n",
        "                    max_length=128,\n",
        "                    return_tensors='pt'\n",
        "                )\n",
        "                encodings = {k: v.to(device) for k, v in encodings.items()}\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(**encodings)\n",
        "                preds = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "                # Move predictions back to CPU and extend list\n",
        "                predictions.extend(preds.cpu().tolist())\n",
        "\n",
        "        return predictions\n",
        "    else:\n",
        "        raise NotImplementedError(f\"Algorithm {m['algo_num']} not implemented in predict function\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37c68e29",
      "metadata": {
        "id": "37c68e29"
      },
      "outputs": [],
      "source": [
        "predictions = predict(Bert_model, 'trump_tweets_test_a.tsv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28313157",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28313157",
        "outputId": "21db7c02-314e-4f9b-c35e-09411076c592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions: [1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]\n"
          ]
        }
      ],
      "source": [
        "print(\"Predictions:\", predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdc7f1f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdc7f1f7",
        "outputId": "5822f4f1-7f8a-49f5-81c3-bc3eb4edb8dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 200 predictions to predictions.txt\n"
          ]
        }
      ],
      "source": [
        "# Save predictions to a file, one label per line\n",
        "output_path = \"predictions.txt\"\n",
        "with open(output_path, \"w\") as f:\n",
        "    for label in predictions:\n",
        "        f.write(f\"{label}\\n\")\n",
        "print(f\"Saved {len(predictions)} predictions to {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b26b0ce8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def who_am_i():  # this is not a class method\n",
        "    \"\"\"Returns a list of dictionaries, each dictionary with your name, id number and email. keys=['name', 'id','email']\n",
        "        (If you are submitting solo, the list should contain only one dictionary. If you submit as a team, the list should\n",
        "        contain a dictionary for each team member.)\n",
        "        Make sure you return your own info!\n",
        "    \"\"\"\n",
        "    return [{'name': 'Mickael Zeitoun', 'id': '328783105', 'email': 'mickaelz@post.bgu.ac.il'},{'name': 'Dor Meir', 'id': '313254724', 'email': 'dorgalon@post.bgu.ac.il'}]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (my_enviro)",
      "language": "python",
      "name": "my_enviro"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00ad7be748b2416fa0215549e0855ebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0246f5ae5cc1413f92d51962fd475562": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13fca8733cd44a6887226d74d3a6b7c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15b64fc8cc3b481da0f2a2f1e3a4dd50": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "194deb9f928a41c9a5914c3d32215a84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a8ab8027fcc4d30ba332bfd53a71af3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c6b31675aa2404791e1049536697fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d1c6dc3f27c4a819f84531ef1f3b60c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ed34168f8e24861a89ab3ab47550695": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_297e2dcacb7d416ebc48aeb4de11dc61",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0246f5ae5cc1413f92d51962fd475562",
            "value": "config.json:â€‡100%"
          }
        },
        "27d874f6f9b44bc2864a4eba1b9447d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "297e2dcacb7d416ebc48aeb4de11dc61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f8e1284cf064ff7983cef37265a82cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "316a6ef6eeb141298a4275f52777c5fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cb21ac81a0b4bada1ddea6f68f3ed79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d1c6dc3f27c4a819f84531ef1f3b60c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ef8d6f08cb134b0c941b735ca8e95752",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "4a13fffd5d8a4e878765dcb2eca6b2f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d0ace50563547f08e9477bb036c0fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f029fb90af04d1397991106f861dc23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c4348a97d6642f2b98ffc77657b984c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f577e490cdb9422a8b16db19148e186c",
            "value": "vocab.txt:â€‡100%"
          }
        },
        "4f05783446944bdb91a9d25db73e34cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ed34168f8e24861a89ab3ab47550695",
              "IPY_MODEL_f1366898c1804be08b804d46e679d6e8",
              "IPY_MODEL_d4a80a6fac034d42b468c38f81f81205"
            ],
            "layout": "IPY_MODEL_d674af637bfb4cf0b1b03109a762bd11"
          }
        },
        "50a9af899cd141dabe42f50e2523bd90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f029fb90af04d1397991106f861dc23",
              "IPY_MODEL_901d90f4be8446b3ad05826f81586f82",
              "IPY_MODEL_9a33a68c5b9c417c8312ac5ae7f128a6"
            ],
            "layout": "IPY_MODEL_194deb9f928a41c9a5914c3d32215a84"
          }
        },
        "55f57d49638349ef975e254c1b5ae601": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "576bb5ece5a74b099cb22a02a73cab01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "587b4919427e4a1d836a0bd9b92dabb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c4348a97d6642f2b98ffc77657b984c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d43f49cc0b941c8988264c583a25be9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6921d34827b847a8867c3e7fa2105ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfab020a77e04efe8136bed7febb9f42",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_826b7474506e459d91a5473623c9597e",
            "value": 48
          }
        },
        "695be64fc1204bf39cc2847f505a6667": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d43f49cc0b941c8988264c583a25be9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_00ad7be748b2416fa0215549e0855ebe",
            "value": "â€‡48.0/48.0â€‡[00:00&lt;00:00,â€‡5.31kB/s]"
          }
        },
        "69a0b69e99bd4332ad9088ae56cf4c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_576bb5ece5a74b099cb22a02a73cab01",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4a13fffd5d8a4e878765dcb2eca6b2f5",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "6baa64eafe994b0590454f912666e6bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce8aa99d6c1b4e07a0513eb4b1aa4e1b",
              "IPY_MODEL_85f23048627345f5a037e7531bc69a3f",
              "IPY_MODEL_9ce77069b1ea47dabf5e9cb22c163b47"
            ],
            "layout": "IPY_MODEL_d8e9252678c24e6e822a848efd98e1ff"
          }
        },
        "6e558f3473eb4705914b1dc2ba73dfab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ca7c7f30ac549c9a8c78ec019880f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "826b7474506e459d91a5473623c9597e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85f23048627345f5a037e7531bc69a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13fca8733cd44a6887226d74d3a6b7c5",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27d874f6f9b44bc2864a4eba1b9447d0",
            "value": 267954768
          }
        },
        "8fd2700f302b4c82b323c266f5e126a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cb21ac81a0b4bada1ddea6f68f3ed79",
              "IPY_MODEL_6921d34827b847a8867c3e7fa2105ffb",
              "IPY_MODEL_695be64fc1204bf39cc2847f505a6667"
            ],
            "layout": "IPY_MODEL_df7697041855484f8eb0f567ffa4c7bd"
          }
        },
        "901d90f4be8446b3ad05826f81586f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b839837cde3c46b3813a9691217288fb",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55f57d49638349ef975e254c1b5ae601",
            "value": 231508
          }
        },
        "95f34338c88047a383af29771d94d621": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_316a6ef6eeb141298a4275f52777c5fd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b714e757297f4ec29baf09d051c64f5b",
            "value": "â€‡466k/466kâ€‡[00:00&lt;00:00,â€‡6.68MB/s]"
          }
        },
        "9a33a68c5b9c417c8312ac5ae7f128a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a8ab8027fcc4d30ba332bfd53a71af3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7ca7c7f30ac549c9a8c78ec019880f11",
            "value": "â€‡232k/232kâ€‡[00:00&lt;00:00,â€‡7.06MB/s]"
          }
        },
        "9ce77069b1ea47dabf5e9cb22c163b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e558f3473eb4705914b1dc2ba73dfab",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c4c097c0f1854c21b76152edca5503b4",
            "value": "â€‡268M/268Mâ€‡[00:01&lt;00:00,â€‡160MB/s]"
          }
        },
        "b714e757297f4ec29baf09d051c64f5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b839837cde3c46b3813a9691217288fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfab020a77e04efe8136bed7febb9f42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4c097c0f1854c21b76152edca5503b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce8aa99d6c1b4e07a0513eb4b1aa4e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_587b4919427e4a1d836a0bd9b92dabb5",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f51661ccc63a4d59b61c955a4621a2e0",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "d05ef473472d451e85b5888d67145670": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69a0b69e99bd4332ad9088ae56cf4c3a",
              "IPY_MODEL_e07b81a4d10c4fbca6b2b6fc91f352a5",
              "IPY_MODEL_95f34338c88047a383af29771d94d621"
            ],
            "layout": "IPY_MODEL_2f8e1284cf064ff7983cef37265a82cd"
          }
        },
        "d4a80a6fac034d42b468c38f81f81205": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15b64fc8cc3b481da0f2a2f1e3a4dd50",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1c6b31675aa2404791e1049536697fc9",
            "value": "â€‡483/483â€‡[00:00&lt;00:00,â€‡60.4kB/s]"
          }
        },
        "d674af637bfb4cf0b1b03109a762bd11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8e9252678c24e6e822a848efd98e1ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df7697041855484f8eb0f567ffa4c7bd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e07b81a4d10c4fbca6b2b6fc91f352a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8871bc472004a61919aa4162b5d3a92",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff0dbacd05bf40b9bf0e91030ca0942e",
            "value": 466062
          }
        },
        "ef8d6f08cb134b0c941b735ca8e95752": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1366898c1804be08b804d46e679d6e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa812637134242c5bab375c7fdb7a298",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d0ace50563547f08e9477bb036c0fe5",
            "value": 483
          }
        },
        "f51661ccc63a4d59b61c955a4621a2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f577e490cdb9422a8b16db19148e186c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8871bc472004a61919aa4162b5d3a92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa812637134242c5bab375c7fdb7a298": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff0dbacd05bf40b9bf0e91030ca0942e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
